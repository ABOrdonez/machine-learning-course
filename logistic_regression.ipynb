{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Aprendizaje supervisado: regresión vs. clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Regresión:\n",
    "- Valor de una propiedad\n",
    "- Cotización de una determinada acción en un mercado\n",
    "- Cantidad de productos comprados\n",
    "\n",
    "### Clasificación:\n",
    "- Email: spam/no spam\n",
    "- Tweet: positivo/negativo\n",
    "- Alumno: aprueba/desaprueba\n",
    "\n",
    "#### Por convención: 1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](files/images/linear_regression_intro_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](files/images/linear_regression_intro_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](files/images/linear_regression_intro_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](files/images/linear_regression_intro_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regresión logística\n",
    "\n",
    "Queremos: $ 0 \\leq h_\\theta (x) \\leq 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Función sigmoide o logística\n",
    "\n",
    "![](files/images/sigmoid_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Antes:\n",
    "\n",
    "$$ h_\\theta = \\theta^T x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ahora: \n",
    "\n",
    "$$ h_\\theta = g(\\theta^Tx) $$\n",
    "\n",
    "$$ g(z) = \\frac{1}{(1 + e^{-z})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Que es igual a:\n",
    "\n",
    "$$ h_\\theta = \\frac{1}{(1 + e^{- \\theta^T x})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Valores entre 0 y 1\n",
    "\n",
    "![](files/images/thinker.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ h_\\theta = P(y=1 | x; \\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ h_\\theta = P(y=0 | x; \\theta) ? $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¿Etiqueta o número?\n",
    "\n",
    "![](files/images/sigmoid_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ y = 1 \\rightarrow h_\\theta \\geq 0.5 \\rightarrow \\theta^Tx \\geq 0 $$\n",
    "$$ y = 0 \\rightarrow h_\\theta < 0.5 \\rightarrow \\theta^Tx < 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Frontera de decisión\n",
    "![](files/images/decision_boundary_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Si\n",
    "\n",
    "$ \\theta_0 = -3, \\theta_1 = 1, \\theta_2 = 1 $\n",
    "\n",
    "### Podemos pensar entonces que y = 1 cuando \n",
    "$ -3 + x_1 + x_2 >= 0 $\n",
    "\n",
    "### o\n",
    "\n",
    "$ x_1 + x_2 >= 3 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](files/images/decision_boundary_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](files/images/fail.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¿Cómo aprendemos?\n",
    "![](files/images/sigmoid_function_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Optimizar $ \\theta\\ $ !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regresión lineal\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{m} \\sum^{m}_{i=1} \\frac{1}{2} (h_\\theta (x^i) - y^i)^2 $$\n",
    "$$ C(h_\\theta (x), y) = \\frac{1}{2} (h_\\theta(x^i)-y^i)^2 $$\n",
    "\n",
    "### El error cuadrático es una función poco conveniente para nuestro objetivo: no es convexa, por lo tanto presenta muchos mínimos locales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regresión logística\n",
    "\n",
    "$ C(h_\\theta (x), y) = -\\log(h_\\theta(x)) \\qquad si \\quad y = 1 $\n",
    "\n",
    "$ \\qquad \\qquad \\quad -\\log(1-h_\\theta(x)) \\qquad si \\quad y = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](files/images/logs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Si\n",
    "$ h_\\theta = 0 \\qquad pero  \\quad y = 1 $\n",
    "### entonces queremos que C sea muy grande !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ¿Podemos simplificar nuestra función C?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$ C(h_\\theta (x), y) = -\\log(h_\\theta(x)) \\qquad si \\quad y = 1 $\n",
    "\n",
    "$ \\qquad \\qquad \\quad -\\log(1-h_\\theta(x)) \\qquad si \\quad y = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Siempre trabajamos con y = 0 o y = 1, entonces ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ C(h_\\theta (x), y) = -y \\log(h_\\theta(x)) - (1-y) \\log(1-h_\\theta(x)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Finalmente ...\n",
    "\n",
    "$$ J(\\theta) = -\\frac{1}{m} [\\sum^{m}_{i=1} y^i \\log h_\\theta(x^i) + (1-y^i)\\log(1-h_\\theta(x^i))]  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Descenso por el gradiente\n",
    "\n",
    "$ min_\\theta \\quad J(\\theta): $\n",
    "\n",
    "Repetir {\n",
    "\n",
    "$ \\quad \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta) $\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### ¿alguna diferencia con regresión lineal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### siendo ...\n",
    "$\\frac{\\partial}{\\partial \\theta_j} J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^i)-y^i)x_j^i $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regresión lineal vs. logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ h_\\theta (x) = \\theta^Tx $$\n",
    "\n",
    "$$ h_\\theta (x) = \\frac{1}{1+e^{-\\theta^Tx}} $$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
